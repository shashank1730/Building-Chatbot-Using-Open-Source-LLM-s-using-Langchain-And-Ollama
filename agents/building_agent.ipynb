{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d884c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa35fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool - 1 , Here out 1st Tool is Wikipedia \n",
    "api = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638cae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Using cached wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages (from wikipedia) (4.13.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages (from wikipedia) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.4.26)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages (from beautifulsoup4->wikipedia) (4.13.2)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (setup.py): started\n",
      "  Building wheel for wikipedia (setup.py): finished with status 'done'\n",
      "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11785 sha256=c725ac20d46b8070700027dbf98061a182d22be1b6e0fa5cc7d332213a5081a7\n",
      "  Stored in directory: c:\\users\\nalla\\appdata\\local\\pip\\cache\\wheels\\5e\\b6\\c5\\93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'wikipedia' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'wikipedia'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b00a39a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44ff3153",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Libraries needed to fetch the data from URL\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06051593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalla\\AppData\\Local\\Temp\\ipykernel_10736\\2380442911.py:4: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  vectordb_AA_TC = FAISS.from_documents(AA_TC_fecthed_data[:20],OllamaEmbeddings())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001767D20FC70>, search_kwargs={})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_AA_TC = WebBaseLoader(\"https://www.aa.com/i18n/customer-service/support/legal-information.jsp\")\n",
    "AA_TC_data = loader_AA_TC.load()\n",
    "AA_TC_fecthed_data = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(AA_TC_data)\n",
    "vectordb_AA_TC = FAISS.from_documents(AA_TC_fecthed_data[:20],OllamaEmbeddings())\n",
    "AA_TC_retriver = vectordb_AA_TC.as_retriever()\n",
    "AA_TC_retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84c3e52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001767D22D930>, search_kwargs={})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_AA_CC = WebBaseLoader(\"https://www.aa.com/i18n/customer-service/support/conditions-of-carriage.jsp\")\n",
    "AA_CC_data = loader_AA_CC.load()\n",
    "AA_CC_fetched_data = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200).split_documents(AA_CC_data)\n",
    "vectordb_AA_CC = FAISS.from_documents(AA_CC_fetched_data[:20],OllamaEmbeddings())\n",
    "AA_CC_retriver = vectordb_AA_CC.as_retriever()\n",
    "AA_CC_retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "883e64e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool,AA_TC_retriver,AA_CC_retriver]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6da89e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\nalla\\\\anaconda3\\\\envs\\\\myenv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001767D20FC70>, search_kwargs={}),\n",
       " VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001767D22D930>, search_kwargs={})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afe5ccdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OllamaLLM(model='llama2')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"llama2\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb739be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is an optional code to show how to import predefined froms that arae already in a structured and are present in lanchain hub\n",
    "from langchain import hub\n",
    "\n",
    "prompt_demo = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt_demo.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5652c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Act as a refund agent who always helps its customer to get the maximum refund from the context.\n",
    "Many customers have no idea, so read the context (Terms and Conditions of American Airlines)\n",
    "and help the customer on what to talk to customer care to get the maximum refund.\n",
    "You will get 10 percent of every successful refund.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "{agent_scratchpad}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dbbb1e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported function\n\ntags=['FAISS', 'OllamaEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001767D20FC70> search_kwargs={}\n\nFunctions must be passed in as Dict, pydantic.BaseModel, or Callable. If they're a dict they must either be in OpenAI function format or valid JSON schema with top-level 'title' and 'description' keys.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_openai_tools_agent\n\u001b[1;32m----> 2\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_openai_tools_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\agents\\openai_tools\\base.py:95\u001b[0m, in \u001b[0;36mcreate_openai_tools_agent\u001b[1;34m(llm, tools, prompt, strict)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_vars:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt missing required variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m---> 95\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[convert_to_openai_tool(tool, strict\u001b[38;5;241m=\u001b[39mstrict) \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools]\n\u001b[0;32m     96\u001b[0m )\n\u001b[0;32m     98\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     99\u001b[0m     RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m    100\u001b[0m         agent_scratchpad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: format_to_openai_tool_messages(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;241m|\u001b[39m OpenAIToolsAgentOutputParser()\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m agent\n",
      "File \u001b[1;32mc:\\Users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain\\agents\\openai_tools\\base.py:95\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_vars:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt missing required variables: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m llm_with_tools \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m---> 95\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[\u001b[43mconvert_to_openai_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools]\n\u001b[0;32m     96\u001b[0m )\n\u001b[0;32m     98\u001b[0m agent \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     99\u001b[0m     RunnablePassthrough\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m    100\u001b[0m         agent_scratchpad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: format_to_openai_tool_messages(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;241m|\u001b[39m OpenAIToolsAgentOutputParser()\n\u001b[0;32m    107\u001b[0m )\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m agent\n",
      "File \u001b[1;32mc:\\Users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\utils\\function_calling.py:564\u001b[0m, in \u001b[0;36mconvert_to_openai_tool\u001b[1;34m(tool, strict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (tool\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweb_search_preview\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    563\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tool\n\u001b[1;32m--> 564\u001b[0m oai_function \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_openai_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m\"\u001b[39m: oai_function}\n",
      "File \u001b[1;32mc:\\Users\\nalla\\anaconda3\\envs\\myenv\\lib\\site-packages\\langchain_core\\utils\\function_calling.py:488\u001b[0m, in \u001b[0;36mconvert_to_openai_function\u001b[1;34m(function, strict)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    482\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    483\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported function\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFunctions must be passed in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m as Dict, pydantic.BaseModel, or Callable. If they\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre a dict they must\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m either be in OpenAI function format or valid JSON schema with top-level\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keys.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m oai_function \u001b[38;5;129;01mand\u001b[39;00m oai_function[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m strict:\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported function\n\ntags=['FAISS', 'OllamaEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001767D20FC70> search_kwargs={}\n\nFunctions must be passed in as Dict, pydantic.BaseModel, or Callable. If they're a dict they must either be in OpenAI function format or valid JSON schema with top-level 'title' and 'description' keys."
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77109172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
